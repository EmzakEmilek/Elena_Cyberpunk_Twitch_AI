# Elena - Cyberpunk Twitch AI ü§ñ

[English below](#english)

## Slovensky

AI asistentka pre Twitch streamy s podporou viacer√Ωch jazykov pomocou Azure TTS. Predvolene nastaven√° na slovenƒçinu, ale podporuje aj in√© jazyky vƒèaka Whisper STT a Azure TTS. Komunikuje cez mikrof√≥n a reaguje v re√°lnom ƒçase.

### üåç Jazykov√° podpora

#### Speech-to-Text (Whisper)
- Podporuje 99 jazykov vr√°tane v≈°etk√Ωch hlavn√Ωch eur√≥pskych jazykov
- Najbe≈ænej≈°ie k√≥dy jazykov:
  - `sk` - Slovenƒçina
  - `cs` - ƒåe≈°tina
  - `en` - Angliƒçtina
  - `de` - Nemƒçina
  - `pl` - Poƒæ≈°tina
  - `hu` - Maƒèarƒçina
  - `uk` - Ukrajinƒçina
- [Kompletn√Ω zoznam jazykov Whisper](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py#L10)

#### Text-to-Speech (Azure)
- Viac ako 400 hlasov v 100+ jazykoch
- Najbe≈ænej≈°ie hlasy pre n√°≈° regi√≥n:
  ```
  sk-SK-ViktoriaNeural    # Slovenƒçina (≈æena)
  sk-SK-LukasNeural       # Slovenƒçina (mu≈æ)
  cs-CZ-VlastaNeural      # ƒåe≈°tina (≈æena)
  cs-CZ-AntoninNeural     # ƒåe≈°tina (mu≈æ)
  en-US-JennyNeural       # Angliƒçtina US (≈æena)
  en-GB-SoniaNeural       # Angliƒçtina UK (≈æena)
  de-DE-KatjaNeural       # Nemƒçina (≈æena)
  pl-PL-AgnieszkaNeural   # Poƒæ≈°tina (≈æena)
  hu-HU-NoemiNeural       # Maƒèarƒçina (≈æena)
  uk-UA-PolinaNeural      # Ukrajinƒçina (≈æena)
  ```
- [Kompletn√Ω zoznam Azure hlasov](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)

**Zmena jazyka**:
1. V `config.yaml` nastavte `language` pre Whisper
2. V `.env` nastavte `AZURE_SPEECH_VOICE` na po≈æadovan√Ω hlas
3. Odpor√∫ƒçame pou≈æ√≠va≈• rovnak√Ω jazyk pre STT aj TTS

### üí∞ Cenov√© inform√°cie

Projekt vyu≈æ√≠va platen√© slu≈æby:

#### OpenAI Assistant API
- Vy≈æaduje platen√Ω OpenAI √∫ƒçet
- Assistant API s GPT-4-0125-preview (4.0-mini):
  - Input: $0.003 za 1K tokenov
  - Output: $0.006 za 1K tokenov
- Pri 40-min√∫tovom streame (cca 100 interakci√≠):
  - Pribli≈æne $0.80-1.50 za stream (z√°le≈æ√≠ od dƒ∫≈æky odpoved√≠)

#### Azure Speech Services
- Pon√∫ka free tier: 500,000 znakov mesaƒçne zadarmo
- Po vyƒçerpan√≠ free kreditu:
  - Neural TTS: $16 za 1M znakov
  - Pri 100 odpovediach (cca 20,000 znakov): ~$0.32
- Regi√≥n "West Europe" m√° v√Ωhodn√∫ latenciu pre SK/CZ

‚ö†Ô∏è Odpor√∫ƒçame sledova≈• usage v dashboarde OpenAI a Azure, aby nedo≈°lo k neƒçakan√Ωm poplatkom.

### ‚ú® Kƒæ√∫ƒçov√© vlastnosti

- üé§ **Push-to-Talk**: Stlaƒç a dr≈æ F12 pre nahr√°vanie
- üéØ **R√Ωchla odozva**: Speech-to-Text aj generovanie odpovede do p√°r sek√∫nd 
- üó£Ô∏è **Kvalitn√Ω slovensk√Ω hlas**: Azure Neural TTS (Vikt√≥ria)
- ‚ö° **GPU akceler√°cia**: Whisper STT be≈æ√≠ na CUDA
- üìä **Live metriky**: ƒåasy transkripcie a generovania odpovede
- üé® **Prehƒæadn√© UI**: Farebn√Ω v√Ωstup v termin√°li s emoji

### üèóÔ∏è Architekt√∫ra

```mermaid
graph LR
    A[Mikrof√≥n] -->|Audio Stream| B[Audio Processor]
    B -->|WAV Data| C[Whisper STT]
    C -->|Text| D[OpenAI Assistant]
    D -->|Odpoveƒè| E[Azure TTS]
    E -->|Audio| F[Reproduktory]
```

#### Komponenty
1. **Audio Processor** (`services/audio_processor.py`)
   - Nahr√°va a spracov√°va audio stream
   - Detekcia hlasovej aktivity (VAD)
   - Buffer management

2. **Speech-to-Text** (`core/pipeline.py`)
   - Whisper model pre transkripciu
   - CUDA akceler√°cia
   - Jazykov√° detekcia

3. **AI Assistant** (`services/assistant.py`)
   - OpenAI GPT Assistant API
   - Kontextov√© spracovanie
   - Generovanie odpoved√≠

4. **Text-to-Speech** (`services/tts/azure_tts.py`)
   - Azure Neural TTS
   - Voice management
   - Audio synthesis queue

#### D√°tov√Ω tok
1. Audio je zachyten√© v 16kHz/16-bit form√°te
2. Whisper spracuje audio do textu
3. Text je poslan√Ω do GPT Assistant API
4. Odpoveƒè je syntetizovan√° cez Azure TTS
5. Audio je prehran√© cez v√Ωstupn√© zariadenie

### üõ†Ô∏è Po≈æiadavky

- Python 3.11+
- NVIDIA GPU (pre CUDA akceler√°ciu)
- OpenAI API kƒæ√∫ƒç (pre GPT asistenta)
- Azure Speech Services kƒæ√∫ƒç (pre TTS)
- Mikrof√≥n a sl√∫chadl√°/reproduktory

### üì¶ In≈°tal√°cia a spustenie

1. **Vytvorte a aktivujte prostredie:**
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

2. **Nain≈°talujte z√°vislosti:**
```bash
pip install -r requirements.txt
```

3. **Nastavte premenn√© prostredia:**
   - Skop√≠rujte `.env.example` do `.env`
   - Vypl≈àte API kƒæ√∫ƒçe pre OpenAI a Azure
   - Nastavte ASSISTANT_ID

4. **Spustite aplik√°ciu:**
```bash
python main.py
```

### üéÆ Pou≈æitie

- **Stlaƒç a dr≈æ F12** pre zaƒçiatok nahr√°vania
- **Pusti F12** pre spracovanie a odpoveƒè
- **Ctrl+C** v termin√°li pre ukonƒçenie

### üìä Metriky a Monitoring

Pri ka≈ædej interakcii sa zobrazuj√∫:

- **ƒåas transkripcie**: Typicky 0.8-1.5s
- **ƒåas odpovede**: Typicky 4-7s
- **Celkov√Ω ƒças**: S√∫ƒçet v≈°etk√Ωch oper√°ci√≠
- **Detekovan√Ω jazyk**: Jazyk + istota detekcie
- **Poƒçet slov**: Pre transkripciu aj odpoveƒè

### üìù Logovanie

Logy sa ukladaj√∫ do `logs/elena_stt_YYYYMMDD_HHMMSS.log` a obsahuj√∫:
- Inicializ√°ciu slu≈æieb
- Transkripcie a odpovede
- Chybov√© stavy
- Metriky a ƒçasovanie

### ‚öôÔ∏è Detailn√° konfigur√°cia

#### Model (Whisper)
```yaml
model:
  size: "large-v2"         # Mo≈ænosti: tiny, base, small, medium, large-v2
  language: "sk"           # K√≥d jazyka (napr. sk, en, de, cs, ...)
  cuda:
    enabled: true         # GPU akceler√°cia
    compute_type: "float16"  # Mo≈ænosti: float32, float16, int8
  cpu:
    compute_type: "int8"   # CPU fallback konfigur√°cia
  inference:
    beam_size: 5          # Beam search ≈°√≠rka
    best_of: 5            # Poƒçet kandid√°tov
    temperature: 0.0      # Sampling teplota (0.0 = deterministick√©)
    vad_filter: true      # Detekcia ticha
    no_speech_threshold: 0.6  # Prah pre "ticho"
```

#### Audio
```yaml
audio:
  sample_rate: 16000      # Vzorkovacia frekvencia (Hz)
  channels: 1             # Mono audio
  blocksize: 1024         # ~64ms pri 16kHz
  pre_roll_sec: 0.25      # Nahr√°vanie pred prv√Ωm zvukom
  post_roll_sec: 0.25     # Dobeh po pusten√≠ PTT
  input_device_index: null # null = predvolen√Ω mikrof√≥n
```

#### Ovl√°danie
```yaml
controls:
  ptt_key: "f12"         # Push-to-talk kl√°vesa
  print_partials: false   # Debug priebe≈æn√Ωch v√Ωsledkov
```

#### Text-to-Speech
```yaml
tts:
  enabled: true          # Azure TTS
  provider: "azure"      # TTS provider
  voice: "sk-SK-ViktoriaNeural"
  rate: 1.0             # R√Ωchlos≈• reƒçi (0.5 - 2.0)
  pitch: 0.0            # V√Ω≈°ka hlasu (-2.0 - 2.0)
  volume: 1.0           # Hlasitos≈• (0.0 - 2.0)
  queue:
    max_size: 10        # Maxim√°lna veƒækos≈• fronty
```

### üîß Pokroƒçil√© nastavenia

#### Environment Variables
```bash
# OpenAI
OPENAI_API_KEY=your_key    # OpenAI API kƒæ√∫ƒç
ASSISTANT_ID=asst_xxx      # ID pripraven√©ho asistenta

# Azure Speech
AZURE_SPEECH_KEY=your_key  # Azure Speech Services kƒæ√∫ƒç
AZURE_SPEECH_REGION=westeurope
AZURE_SPEECH_VOICE=sk-SK-ViktoriaNeural
```

#### Audio zariadenia
Pre v√Ωpis dostupn√Ωch zariaden√≠:
```bash
python -m sounddevice
```

#### CUDA Optimaliz√°cia
Pre najlep≈°√≠ v√Ωkon:
- CUDA 11.8+
- cuDNN 8.9.7+
- PyTorch s CUDA podporou
- GPU s aspo≈à 4GB VRAM

### üêõ Debug re≈æim

Pre detailn√© logovanie:
```bash
python main.py --debug
```

U≈æitoƒçn√© inform√°cie v debug m√≥de:
- CUDA dostupnos≈• a verzia
- Audio device konfigur√°cia
- API latencie
- Memory usage
- Partial results

### ‚ö†Ô∏è Rie≈°enie probl√©mov

1. **No CUDA device available**
   - Skontrolujte `nvidia-smi`
   - Overte CUDA toolkit in≈°tal√°ciu
   - Prejdite na CPU m√≥d v config.yaml

2. **Audio zariadenie nen√°jden√©**
   - Skontrolujte `python -m sounddevice`
   - Nastavte explicitn√Ω `input_device_index`

3. **TTS zlyhania**
   - Overte Azure kredity a kv√≥ty
   - Skontrolujte internet pripojenie
   - Pozrite logy pre detaily

4. **Vysok√° latencia**
   - Zn√≠≈æte Whisper model size
   - Zapnite CUDA akceler√°ciu
   - Upravte audio parametre

---

## English

An AI assistant for Twitch streams with multi-language support using Azure TTS. Preconfigured for Slovak but supports various languages through Whisper STT and Azure TTS. Communicates via microphone and responds in real-time.

### üåç Language Support

#### Speech-to-Text (Whisper)
- Supports 99 languages including all major European languages
- Most common language codes:
  - `sk` - Slovak
  - `cs` - Czech
  - `en` - English
  - `de` - German
  - `pl` - Polish
  - `hu` - Hungarian
  - `uk` - Ukrainian
- [Complete Whisper language list](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py#L10)

#### Text-to-Speech (Azure)
- Over 400 voices in 100+ languages
- Most common voices for our region:
  ```
  sk-SK-ViktoriaNeural    # Slovak (female)
  sk-SK-LukasNeural       # Slovak (male)
  cs-CZ-VlastaNeural      # Czech (female)
  cs-CZ-AntoninNeural     # Czech (male)
  en-US-JennyNeural       # English US (female)
  en-GB-SoniaNeural       # English UK (female)
  de-DE-KatjaNeural       # German (female)
  pl-PL-AgnieszkaNeural   # Polish (female)
  hu-HU-NoemiNeural       # Hungarian (female)
  uk-UA-PolinaNeural      # Ukrainian (female)
  ```
- [Complete Azure voices list](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)

**Language Change**:
1. Set `language` in `config.yaml` for Whisper
2. Set `AZURE_SPEECH_VOICE` in `.env` to desired voice
3. We recommend using the same language for both STT and TTS

### üí∞ Pricing Information

This project uses paid services:

#### OpenAI Assistant API
- Requires a paid OpenAI account
- Assistant API with GPT-4-0125-preview (4.0-mini):
  - Input: $0.003 per 1K tokens
  - Output: $0.006 per 1K tokens
- For a 40-minute stream (approx. 100 interactions):
  - Approximately $0.80-1.50 per stream (depends on response lengths)

#### Azure Speech Services
- Offers a free tier: 500,000 characters per month free
- After free credit is used:
  - Neural TTS: $16 per 1M characters
  - For 100 responses (approx. 20,000 characters): ~$0.32
- "West Europe" region provides favorable latency for SK/CZ

‚ö†Ô∏è We recommend monitoring usage in both OpenAI and Azure dashboards to avoid unexpected charges.

### ‚ú® Key Features

- üé§ **Push-to-Talk**: Press and hold F12 to record
- üéØ **Quick Response**: Speech-to-Text and response generation within seconds
- üó£Ô∏è **Quality Slovak Voice**: Azure Neural TTS (Victoria)
- ‚ö° **GPU Acceleration**: Whisper STT runs on CUDA
- üìä **Live Metrics**: Transcription and response generation times
- üé® **Clear UI**: Colorful terminal output with emoji

### üèóÔ∏è Architecture

```mermaid
graph LR
    A[Microphone] -->|Audio Stream| B[Audio Processor]
    B -->|WAV Data| C[Whisper STT]
    C -->|Text| D[OpenAI Assistant]
    D -->|Response| E[Azure TTS]
    E -->|Audio| F[Speakers]
```

#### Components
1. **Audio Processor** (`services/audio_processor.py`)
   - Records and processes audio stream
   - Voice Activity Detection (VAD)
   - Buffer management

2. **Speech-to-Text** (`core/pipeline.py`)
   - Whisper model for transcription
   - CUDA acceleration
   - Language detection

3. **AI Assistant** (`services/assistant.py`)
   - OpenAI GPT Assistant API
   - Context processing
   - Response generation

4. **Text-to-Speech** (`services/tts/azure_tts.py`)
   - Azure Neural TTS
   - Voice management
   - Audio synthesis queue

#### Data Flow
1. Audio is captured in 16kHz/16-bit format
2. Whisper processes audio to text
3. Text is sent to GPT Assistant API
4. Response is synthesized via Azure TTS
5. Audio is played through output device

### üõ†Ô∏è Requirements

- Python 3.11+
- NVIDIA GPU (for CUDA acceleration)
- OpenAI API key (for GPT assistant)
- Azure Speech Services key (for TTS)
- Microphone and headphones/speakers

### üì¶ Installation and Launch

1. **Create and activate environment:**
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set environment variables:**
   - Copy `.env.example` to `.env`
   - Fill in API keys for OpenAI and Azure
   - Set ASSISTANT_ID

4. **Launch the application:**
```bash
python main.py
```

### üéÆ Usage

- **Press and hold F12** to start recording
- **Release F12** for processing and response
- **Ctrl+C** in terminal to exit

### üìä Metrics and Monitoring

Each interaction displays:

- **Transcription Time**: Typically 0.8-1.5s
- **Response Time**: Typically 4-7s
- **Total Time**: Sum of all operations
- **Detected Language**: Language + detection confidence
- **Word Count**: For both transcription and response

### üìù Logging

Logs are saved to `logs/elena_stt_YYYYMMDD_HHMMSS.log` and contain:
- Service initialization
- Transcriptions and responses
- Error states
- Metrics and timing

### ‚öôÔ∏è Detailed Configuration

#### Model (Whisper)
```yaml
model:
  size: "large-v2"         # Options: tiny, base, small, medium, large-v2
  language: "sk"           # Language code (e.g., sk, en, de, cs, ...)
  cuda:
    enabled: true         # GPU acceleration
    compute_type: "float16"  # Options: float32, float16, int8
  cpu:
    compute_type: "int8"   # CPU fallback configuration
  inference:
    beam_size: 5          # Beam search width
    best_of: 5            # Number of candidates
    temperature: 0.0      # Sampling temperature (0.0 = deterministic)
    vad_filter: true      # Silence detection
    no_speech_threshold: 0.6  # Threshold for "silence"
```

#### Audio
```yaml
audio:
  sample_rate: 16000      # Sampling frequency (Hz)
  channels: 1             # Mono audio
  blocksize: 1024         # ~64ms at 16kHz
  pre_roll_sec: 0.25      # Recording before first sound
  post_roll_sec: 0.25     # Tail after PTT release
  input_device_index: null # null = default microphone
```

#### Controls
```yaml
controls:
  ptt_key: "f12"         # Push-to-talk key
  print_partials: false   # Debug intermediate results
```

#### Text-to-Speech
```yaml
tts:
  enabled: true          # Azure TTS
  provider: "azure"      # TTS provider
  voice: "sk-SK-ViktoriaNeural"
  rate: 1.0             # Speech rate (0.5 - 2.0)
  pitch: 0.0            # Voice pitch (-2.0 - 2.0)
  volume: 1.0           # Volume (0.0 - 2.0)
  queue:
    max_size: 10        # Maximum queue size
```

### üîß Advanced Settings

#### Environment Variables
```bash
# OpenAI
OPENAI_API_KEY=your_key    # OpenAI API key
ASSISTANT_ID=asst_xxx      # ID of prepared assistant

# Azure Speech
AZURE_SPEECH_KEY=your_key  # Azure Speech Services key
AZURE_SPEECH_REGION=westeurope
AZURE_SPEECH_VOICE=sk-SK-ViktoriaNeural
```

#### Audio Devices
To list available devices:
```bash
python -m sounddevice
```

#### CUDA Optimization
For best performance:
- CUDA 11.8+
- cuDNN 8.9.7+
- PyTorch with CUDA support
- GPU with at least 4GB VRAM

### üêõ Debug Mode

For detailed logging:
```bash
python main.py --debug
```

Useful information in debug mode:
- CUDA availability and version
- Audio device configuration
- API latencies
- Memory usage
- Partial results

### ‚ö†Ô∏è Troubleshooting

1. **No CUDA device available**
   - Check `nvidia-smi`
   - Verify CUDA toolkit installation
   - Switch to CPU mode in config.yaml

2. **Audio device not found**
   - Check `python -m sounddevice`
   - Set explicit `input_device_index`

3. **TTS failures**
   - Verify Azure credits and quotas
   - Check internet connection
   - Look at logs for details

4. **High latency**
   - Reduce Whisper model size
   - Enable CUDA acceleration
   - Adjust audio parameters

### ‚ÑπÔ∏è Contributing

Pull requests s√∫ v√≠tan√©. Pre v√§ƒç≈°ie zmeny, pros√≠m, najprv otvorte issue pre diskusiu.

### üìÑ License

[MIT](https://choosealicense.com/licenses/mit/)
