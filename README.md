# Elena - Cyberpunk Twitch AI ğŸ¤–

[English below](#english)

## Slovensky

AI asistentka pre Twitch streamy s podporou viacerÃ½ch jazykov pomocou Azure TTS. Predvolene nastavenÃ¡ na slovenÄinu, ale podporuje aj inÃ© jazyky vÄaka Whisper STT a Azure TTS. Komunikuje cez mikrofÃ³n a reaguje v reÃ¡lnom Äase.

### ğŸŒ JazykovÃ¡ podpora

#### Speech-to-Text (Whisper)
- Podporuje 99 jazykov vrÃ¡tane vÅ¡etkÃ½ch hlavnÃ½ch eurÃ³pskych jazykov
- NajbeÅ¾nejÅ¡ie kÃ³dy jazykov:
  - `sk` - SlovenÄina
  - `cs` - ÄŒeÅ¡tina
  - `en` - AngliÄtina
  - `de` - NemÄina
  - `pl` - PoÄ¾Å¡tina
  - `hu` - MaÄarÄina
  - `uk` - UkrajinÄina
- [KompletnÃ½ zoznam jazykov Whisper](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py#L10)

#### Text-to-Speech (Azure)
- Viac ako 400 hlasov v 100+ jazykoch
- NajbeÅ¾nejÅ¡ie hlasy pre nÃ¡Å¡ regiÃ³n:
  ```
  sk-SK-ViktoriaNeural    # SlovenÄina (Å¾ena)
  sk-SK-LukasNeural       # SlovenÄina (muÅ¾)
  cs-CZ-VlastaNeural      # ÄŒeÅ¡tina (Å¾ena)
  cs-CZ-AntoninNeural     # ÄŒeÅ¡tina (muÅ¾)
  en-US-JennyNeural       # AngliÄtina US (Å¾ena)
  en-GB-SoniaNeural       # AngliÄtina UK (Å¾ena)
  de-DE-KatjaNeural       # NemÄina (Å¾ena)
  pl-PL-AgnieszkaNeural   # PoÄ¾Å¡tina (Å¾ena)
  hu-HU-NoemiNeural       # MaÄarÄina (Å¾ena)
  uk-UA-PolinaNeural      # UkrajinÄina (Å¾ena)
  ```
- [KompletnÃ½ zoznam Azure hlasov](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)

**Zmena jazyka**:
1. V `config.yaml` nastavte `language` pre Whisper
2. V `.env` nastavte `AZURE_SPEECH_VOICE` na poÅ¾adovanÃ½ hlas
3. OdporÃºÄame pouÅ¾Ã­vaÅ¥ rovnakÃ½ jazyk pre STT aj TTS

### ğŸ’° CenovÃ© informÃ¡cie

Projekt vyuÅ¾Ã­va platenÃ© sluÅ¾by:

#### OpenAI Assistant API
- VyÅ¾aduje platenÃ½ OpenAI ÃºÄet
- Assistant API s GPT-4-0125-preview (4.0-mini):
  - Input: $0.003 za 1K tokenov
  - Output: $0.006 za 1K tokenov
- Pri 40-minÃºtovom streame (cca 100 interakciÃ­):
  - PribliÅ¾ne $0.80-1.50 za stream (zÃ¡leÅ¾Ã­ od dÄºÅ¾ky odpovedÃ­)

#### Azure Speech Services
- PonÃºka free tier: 500,000 znakov mesaÄne zadarmo
- Po vyÄerpanÃ­ free kreditu:
  - Neural TTS: $16 za 1M znakov
  - Pri 100 odpovediach (cca 20,000 znakov): ~$0.32
- RegiÃ³n "West Europe" mÃ¡ vÃ½hodnÃº latenciu pre SK/CZ

âš ï¸ OdporÃºÄame sledovaÅ¥ usage v dashboarde OpenAI a Azure, aby nedoÅ¡lo k neÄakanÃ½m poplatkom.

### âœ¨ KÄ¾ÃºÄovÃ© vlastnosti

- ğŸ¤ **Push-to-Talk**: StlaÄ a drÅ¾ F12 pre nahrÃ¡vanie
- ğŸ¯ **RÃ½chla odozva**: Speech-to-Text aj generovanie odpovede do pÃ¡r sekÃºnd 
- ğŸ—£ï¸ **KvalitnÃ½ slovenskÃ½ hlas**: Azure Neural TTS (ViktÃ³ria)
- âš¡ **GPU akcelerÃ¡cia**: Whisper STT beÅ¾Ã­ na CUDA
- ğŸ“Š **Live metriky**: ÄŒasy transkripcie a generovania odpovede
- ğŸ¨ **PrehÄ¾adnÃ© UI**: FarebnÃ½ vÃ½stup v terminÃ¡li s emoji

### ğŸ› ï¸ PoÅ¾iadavky

- Python 3.11+
- NVIDIA GPU (pre CUDA akcelerÃ¡ciu)
- OpenAI API kÄ¾ÃºÄ (pre GPT asistenta)
- Azure Speech Services kÄ¾ÃºÄ (pre TTS)
- MikrofÃ³n a slÃºchadlÃ¡/reproduktory

### ğŸ“¦ InÅ¡talÃ¡cia a spustenie

1. **Vytvorte a aktivujte prostredie:**
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

2. **NainÅ¡talujte zÃ¡vislosti:**
```bash
pip install -r requirements.txt
```

3. **Nastavte premennÃ© prostredia:**
   - SkopÃ­rujte `.env.example` do `.env`
   - VyplÅˆte API kÄ¾ÃºÄe pre OpenAI a Azure
   - Nastavte ASSISTANT_ID

4. **Spustite aplikÃ¡ciu:**
```bash
python main.py
```

### ğŸ® PouÅ¾itie

- **StlaÄ a drÅ¾ F12** pre zaÄiatok nahrÃ¡vania
- **Pusti F12** pre spracovanie a odpoveÄ
- **Ctrl+C** v terminÃ¡li pre ukonÄenie

### ğŸ“Š Metriky a Monitoring

Pri kaÅ¾dej interakcii sa zobrazujÃº:

- **ÄŒas transkripcie**: Typicky 0.8-1.5s
- **ÄŒas odpovede**: Typicky 4-7s
- **CelkovÃ½ Äas**: SÃºÄet vÅ¡etkÃ½ch operÃ¡ciÃ­
- **DetekovanÃ½ jazyk**: Jazyk + istota detekcie
- **PoÄet slov**: Pre transkripciu aj odpoveÄ

### ğŸ“ Logovanie

Logy sa ukladajÃº do `logs/elena_stt_YYYYMMDD_HHMMSS.log` a obsahujÃº:
- InicializÃ¡ciu sluÅ¾ieb
- Transkripcie a odpovede
- ChybovÃ© stavy
- Metriky a Äasovanie

### âš™ï¸ DetailnÃ¡ konfigurÃ¡cia

#### Model (Whisper)
```yaml
model:
  size: "large-v2"         # MoÅ¾nosti: tiny, base, small, medium, large-v2
  language: "sk"           # KÃ³d jazyka (napr. sk, en, de, cs, ...)
  cuda:
    enabled: true         # GPU akcelerÃ¡cia
    compute_type: "float16"  # MoÅ¾nosti: float32, float16, int8
  cpu:
    compute_type: "int8"   # CPU fallback konfigurÃ¡cia
  inference:
    beam_size: 5          # Beam search Å¡Ã­rka
    best_of: 5            # PoÄet kandidÃ¡tov
    temperature: 0.0      # Sampling teplota (0.0 = deterministickÃ©)
    vad_filter: true      # Detekcia ticha
    no_speech_threshold: 0.6  # Prah pre "ticho"
```

#### Audio
```yaml
audio:
  sample_rate: 16000      # Vzorkovacia frekvencia (Hz)
  channels: 1             # Mono audio
  blocksize: 1024         # ~64ms pri 16kHz
  pre_roll_sec: 0.25      # NahrÃ¡vanie pred prvÃ½m zvukom
  post_roll_sec: 0.25     # Dobeh po pustenÃ­ PTT
  input_device_index: null # null = predvolenÃ½ mikrofÃ³n
```

#### OvlÃ¡danie
```yaml
controls:
  ptt_key: "f12"         # Push-to-talk klÃ¡vesa
  print_partials: false   # Debug priebeÅ¾nÃ½ch vÃ½sledkov
```

#### Text-to-Speech
```yaml
tts:
  enabled: true          # Azure TTS
  provider: "azure"      # TTS provider
  voice: "sk-SK-ViktoriaNeural"
  rate: 1.0             # RÃ½chlosÅ¥ reÄi (0.5 - 2.0)
  pitch: 0.0            # VÃ½Å¡ka hlasu (-2.0 - 2.0)
  volume: 1.0           # HlasitosÅ¥ (0.0 - 2.0)
  queue:
    max_size: 10        # MaximÃ¡lna veÄ¾kosÅ¥ fronty
```

### ğŸ”§ PokroÄilÃ© nastavenia

#### Environment Variables
```bash
# OpenAI
OPENAI_API_KEY=your_key    # OpenAI API kÄ¾ÃºÄ
ASSISTANT_ID=asst_xxx      # ID pripravenÃ©ho asistenta

# Azure Speech
AZURE_SPEECH_KEY=your_key  # Azure Speech Services kÄ¾ÃºÄ
AZURE_SPEECH_REGION=westeurope
AZURE_SPEECH_VOICE=sk-SK-ViktoriaNeural
```

#### Audio zariadenia
Pre vÃ½pis dostupnÃ½ch zariadenÃ­:
```bash
python -m sounddevice
```

#### CUDA OptimalizÃ¡cia
Pre najlepÅ¡Ã­ vÃ½kon:
- CUDA 11.8+
- cuDNN 8.9.7+
- PyTorch s CUDA podporou
- GPU s aspoÅˆ 4GB VRAM

### ğŸ› Debug reÅ¾im

Pre detailnÃ© logovanie:
```bash
python main.py --debug
```

UÅ¾itoÄnÃ© informÃ¡cie v debug mÃ³de:
- CUDA dostupnosÅ¥ a verzia
- Audio device konfigurÃ¡cia
- API latencie
- Memory usage
- Partial results

### âš ï¸ RieÅ¡enie problÃ©mov

1. **No CUDA device available**
   - Skontrolujte `nvidia-smi`
   - Overte CUDA toolkit inÅ¡talÃ¡ciu
   - Prejdite na CPU mÃ³d v config.yaml

2. **Audio zariadenie nenÃ¡jdenÃ©**
   - Skontrolujte `python -m sounddevice`
   - Nastavte explicitnÃ½ `input_device_index`

3. **TTS zlyhania**
   - Overte Azure kredity a kvÃ³ty
   - Skontrolujte internet pripojenie
   - Pozrite logy pre detaily

4. **VysokÃ¡ latencia**
   - ZnÃ­Å¾te Whisper model size
   - Zapnite CUDA akcelerÃ¡ciu
   - Upravte audio parametre

---

## English

An AI assistant for Twitch streams with multi-language support using Azure TTS. Preconfigured for Slovak but supports various languages through Whisper STT and Azure TTS. Communicates via microphone and responds in real-time.

### ğŸŒ Language Support

#### Speech-to-Text (Whisper)
- Supports 99 languages including all major European languages
- Most common language codes:
  - `sk` - Slovak
  - `cs` - Czech
  - `en` - English
  - `de` - German
  - `pl` - Polish
  - `hu` - Hungarian
  - `uk` - Ukrainian
- [Complete Whisper language list](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py#L10)

#### Text-to-Speech (Azure)
- Over 400 voices in 100+ languages
- Most common voices for our region:
  ```
  sk-SK-ViktoriaNeural    # Slovak (female)
  sk-SK-LukasNeural       # Slovak (male)
  cs-CZ-VlastaNeural      # Czech (female)
  cs-CZ-AntoninNeural     # Czech (male)
  en-US-JennyNeural       # English US (female)
  en-GB-SoniaNeural       # English UK (female)
  de-DE-KatjaNeural       # German (female)
  pl-PL-AgnieszkaNeural   # Polish (female)
  hu-HU-NoemiNeural       # Hungarian (female)
  uk-UA-PolinaNeural      # Ukrainian (female)
  ```
- [Complete Azure voices list](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)

**Language Change**:
1. Set `language` in `config.yaml` for Whisper
2. Set `AZURE_SPEECH_VOICE` in `.env` to desired voice
3. We recommend using the same language for both STT and TTS

### ğŸ’° Pricing Information

This project uses paid services:

#### OpenAI Assistant API
- Requires a paid OpenAI account
- Assistant API with GPT-4-0125-preview (4.0-mini):
  - Input: $0.003 per 1K tokens
  - Output: $0.006 per 1K tokens
- For a 40-minute stream (approx. 100 interactions):
  - Approximately $0.80-1.50 per stream (depends on response lengths)

#### Azure Speech Services
- Offers a free tier: 500,000 characters per month free
- After free credit is used:
  - Neural TTS: $16 per 1M characters
  - For 100 responses (approx. 20,000 characters): ~$0.32
- "West Europe" region provides favorable latency for SK/CZ

âš ï¸ We recommend monitoring usage in both OpenAI and Azure dashboards to avoid unexpected charges.

### âœ¨ Key Features

- ğŸ¤ **Push-to-Talk**: Press and hold F12 to record
- ğŸ¯ **Quick Response**: Speech-to-Text and response generation within seconds
- ğŸ—£ï¸ **Quality Slovak Voice**: Azure Neural TTS (Victoria)
- âš¡ **GPU Acceleration**: Whisper STT runs on CUDA
- ğŸ“Š **Live Metrics**: Transcription and response generation times
- ğŸ¨ **Clear UI**: Colorful terminal output with emoji

### ğŸ› ï¸ Requirements

- Python 3.11+
- NVIDIA GPU (for CUDA acceleration)
- OpenAI API key (for GPT assistant)
- Azure Speech Services key (for TTS)
- Microphone and headphones/speakers

### ğŸ“¦ Installation and Launch

1. **Create and activate environment:**
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set environment variables:**
   - Copy `.env.example` to `.env`
   - Fill in API keys for OpenAI and Azure
   - Set ASSISTANT_ID

4. **Launch the application:**
```bash
python main.py
```

### ğŸ® Usage

- **Press and hold F12** to start recording
- **Release F12** for processing and response
- **Ctrl+C** in terminal to exit

### ğŸ“Š Metrics and Monitoring

Each interaction displays:

- **Transcription Time**: Typically 0.8-1.5s
- **Response Time**: Typically 4-7s
- **Total Time**: Sum of all operations
- **Detected Language**: Language + detection confidence
- **Word Count**: For both transcription and response

### ğŸ“ Logging

Logs are saved to `logs/elena_stt_YYYYMMDD_HHMMSS.log` and contain:
- Service initialization
- Transcriptions and responses
- Error states
- Metrics and timing

### âš™ï¸ Detailed Configuration

#### Model (Whisper)
```yaml
model:
  size: "large-v2"         # Options: tiny, base, small, medium, large-v2
  language: "sk"           # Language code (e.g., sk, en, de, cs, ...)
  cuda:
    enabled: true         # GPU acceleration
    compute_type: "float16"  # Options: float32, float16, int8
  cpu:
    compute_type: "int8"   # CPU fallback configuration
  inference:
    beam_size: 5          # Beam search width
    best_of: 5            # Number of candidates
    temperature: 0.0      # Sampling temperature (0.0 = deterministic)
    vad_filter: true      # Silence detection
    no_speech_threshold: 0.6  # Threshold for "silence"
```

#### Audio
```yaml
audio:
  sample_rate: 16000      # Sampling frequency (Hz)
  channels: 1             # Mono audio
  blocksize: 1024         # ~64ms at 16kHz
  pre_roll_sec: 0.25      # Recording before first sound
  post_roll_sec: 0.25     # Tail after PTT release
  input_device_index: null # null = default microphone
```

#### Controls
```yaml
controls:
  ptt_key: "f12"         # Push-to-talk key
  print_partials: false   # Debug intermediate results
```

#### Text-to-Speech
```yaml
tts:
  enabled: true          # Azure TTS
  provider: "azure"      # TTS provider
  voice: "sk-SK-ViktoriaNeural"
  rate: 1.0             # Speech rate (0.5 - 2.0)
  pitch: 0.0            # Voice pitch (-2.0 - 2.0)
  volume: 1.0           # Volume (0.0 - 2.0)
  queue:
    max_size: 10        # Maximum queue size
```

### ğŸ”§ Advanced Settings

#### Environment Variables
```bash
# OpenAI
OPENAI_API_KEY=your_key    # OpenAI API key
ASSISTANT_ID=asst_xxx      # ID of prepared assistant

# Azure Speech
AZURE_SPEECH_KEY=your_key  # Azure Speech Services key
AZURE_SPEECH_REGION=westeurope
AZURE_SPEECH_VOICE=sk-SK-ViktoriaNeural
```

#### Audio Devices
To list available devices:
```bash
python -m sounddevice
```

#### CUDA Optimization
For best performance:
- CUDA 11.8+
- cuDNN 8.9.7+
- PyTorch with CUDA support
- GPU with at least 4GB VRAM

### ğŸ› Debug Mode

For detailed logging:
```bash
python main.py --debug
```

Useful information in debug mode:
- CUDA availability and version
- Audio device configuration
- API latencies
- Memory usage
- Partial results

### âš ï¸ Troubleshooting

1. **No CUDA device available**
   - Check `nvidia-smi`
   - Verify CUDA toolkit installation
   - Switch to CPU mode in config.yaml

2. **Audio device not found**
   - Check `python -m sounddevice`
   - Set explicit `input_device_index`

3. **TTS failures**
   - Verify Azure credits and quotas
   - Check internet connection
   - Look at logs for details

4. **High latency**
   - Reduce Whisper model size
   - Enable CUDA acceleration
   - Adjust audio parameters

### â„¹ï¸ Contributing

Pull requests sÃº vÃ­tanÃ©. Pre vÃ¤ÄÅ¡ie zmeny, prosÃ­m, najprv otvorte issue pre diskusiu.

### ğŸ“„ License

[MIT](https://choosealicense.com/licenses/mit/)
